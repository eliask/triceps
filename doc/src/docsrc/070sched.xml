<?xml version="1.0" encoding="UTF-8"?>

<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.5CR3//EN"
	"http://www.oasis-open.org/docbook/xml/4.5CR3/docbookx.dtd" [
<!ENTITY % userents SYSTEM "file:///ENTS/user.ent" >
%userents;
]>

<!--
(C) Copyright 2011-2012 Sergey A. Babkin.
This file is a part of Triceps.
See the file COPYRIGHT for the copyright notice and license information
-->

<chapter id="ch_scheduling" xmlns:xi="http://www.w3.org/2001/XInclude">
	<title>Scheduling</title>

	<sect1 id="sc_sched_overview">
		<title>Overview of the scheduling</title>

		<indexterm>
			<primary>scheduling</primary>
		</indexterm>
		<indexterm>
			<primary>model</primary>
		</indexterm>
		<para>
		The scheduling determines, in which order the row operations are
		processed. If there are multiple operations available, which one
		should be processed first?  The scheduler keeps a queue of the operations
		and selects, which one to execute next.  This has a major effect on the
		logic of a CEP model.  
		</para>

		<indexterm>
			<primary>Aleri</primary>
		</indexterm>
		<indexterm>
			<primary>Coral8</primary>
		</indexterm>
		<indexterm>
			<primary>Sybase</primary>
		</indexterm>
		<indexterm>
			<primary>StreamBase</primary>
		</indexterm>
		<para>
		There are multiple approaches to scheduling. Aleri essentially doesn't
		have any, except for the flow control between threads, because each its
		element is a separate thread. Coral8 has an intricate scheduling
		algorithm. Sybase R5 has the same logic as Coral8 inside each thread.
		StreamBase presumably also has some.
		</para>

		<para>
		The scheduling logic in Triceps is different from the other CEP
		systems. The Coral8 logic looks at first like the only reasonable way
		to go, but could not be used in Triceps for three reasons: First, it's a trade
		secret, so it can't be simply reused. If I'd never seen it, that would
		not be an issue but I've worked on it and implemented its version for
		R5. Second, it relies on the properties that the compiler computes from
		the model graph analysis. Triceps has no compiler, and could not do
		this. Third, in reality it simply doesn't work that well. There are
		quite a few cases when the Coral8 scheduler comes up with a strange and
		troublesome execution order.
		</para>

		<para>
		For a while I've hoped that Triceps would need no scheduler at all, and
		everything would be handled by the procedural calls. This has proved to
		have its own limitations, and thus the labels and their scheduling were
		born. The Triceps scheduling still has issues to resolve, but overall
		it still feels much better than the Coral8 one.
		</para>
	</sect1>

	<sect1 id="sc_sched_no_bundling">
		<title>No bundling</title>

		<para>
		The most important principle of Triceps scheduling is: No Bundling.
		Every rowop is for itself. The bundling is what messes up the Coral8
		scheduler the most. 
		</para>

		<para>
		What is a bundle? It's a set of records that go through the execution
		together. If you have a model consisting of two functional elements F1
		and F2 connected in a sequential fashion 
		</para>

<pre>
F1->F2 
</pre>

		<para>
		and a few loose records R1, R2, R3, the
		normal execution order without bundling will be:
		</para>

<pre>
F1(R1), F2(R1), F1(R2), F2(R2), F1(R3), F2(R3)
</pre>

		<para>
		Each row goes through the whole model (a real simple one in this case)
		before the next one is touched. This allows F2 to take into
		accont the state of F1 exactly as it was right after processing
		the same record, without any interventions in between.
		</para>

		<para>
		If the same records are placed in a bundle (R1, R2, R3), the execution
		order will be different:
		</para>

<pre>
F1(R1), F1(R2), F1(R3), F2(R1), F2(R2), F2(R3)
</pre>

		<para>
		The whole bundle goes through F1 before the rows go to F2.
		</para>

		<para>
		That would not be a problem, and even could be occasionally useful, if
		the bundles were always created explicitly. In the reality of Coral8,
		every time a statement produces multiple record from a single one
		(think of a join that picks multiple records from another side), it
		creates a bundle and messes up all the logic after it. Some logic gets
		affected so badly that a few statements in CCL (like ON UPDATE) had to
		be designated as always ignoring the bundles, otherwise they would not
		work at all. At DB I wrote a CCL pattern for breaking up the bundles.
		It's rather heavyweight and thus could not be used all over the place
		but provides a generic solution for the most unpleasant cases.
		</para>

		<para>
		Worse yet, the bundles may get created in Coral8 absolutely
		accidentally: if two records happen to have the same timestamp, for all
		practical purposes they would act as a bundle. In the models that were
		designed without the appropriate guards, this leads to the time-based
		bugs that are hard to catch and debug. Writing these guards correctly
		is hard, and testing them is even harder. 
		</para>

		<para>
		Another issue with bundles is that they make the large queries slower.
		Suppose you do a query from a window that returns a million
		records. All of them will be collected in a bundle, then the
		bundle will be sent to the interface gateway that would build one huge
		protocol packet, which will then be sent to the client, which will
		receive the whole packet and then finally iterate on the records in it.
		Assuming that nothing runs out of memory along the way, it will be a
		long time until the client sees the first record. Very, very
		annoying.
		</para>

		<para>
		Aleri also has its own version of bundles, called transactions, but a
		more smart one. Aleri always relies on the primary keys. The condition
		for a transaction is that it must never contain multiple modification
		for the same primary key. Since there are no execution order guarantees
		between the functional elements, in this respect the transactions work
		in the same way as loose records, only with a more efficient
		communication between threads. Still, if the primary key changes in an
		element (say, an aggregator), the condition does not propagate through
		it. Such elements have to internally collapse the outgoing transactions
		along the new key, adding overhead.
		</para>
	</sect1>

	<sect1 id="sc_sched_basic">
		<title>Basic scheduling in Triceps</title>

		<para>
		In Triceps the scheduling is done by the execution unit, or simply
		<quote>unit</quote> as it's often referred to.
		It provides 3 basic ways of executing of a rowop:
		</para>

		<indexterm>
			<primary>unit</primary>
		</indexterm>
		<indexterm>
			<primary>row operation</primary>
		</indexterm>
		<variablelist>
			<varlistentry>
				<term>Call:</term>
				<listitem>
				<indexterm>
					<primary>call</primary>
				</indexterm>
				<para>
				Execute the label right now, including all the nested calls.
				All of this will be completed after the call returns.
				</para>
				</listitem>
			</varlistentry>
			<varlistentry>
				<term>Fork:</term>
				<listitem>
				<indexterm>
					<primary>fork</primary>
				</indexterm>
				<para>
				Execute the label after the current label returns but
				before anything else is done. Obviously, if multiple labels are
				forked, they will execute in order after the current label
				returns (but before its caller gets the control back).
				This method has looked promising at one point but has currently
				fallen out of favor and will likely be removed in the future.
				</para>
				</listitem>
			</varlistentry>
			<varlistentry>
				<term>Schedule:</term>
				<listitem>
				<indexterm>
					<primary>schedule</primary>
				</indexterm>
				<para>
				Execute the label after everything else is done.
				</para>
				</listitem>
			</varlistentry>
		</variablelist>

		<para>
		This is kind of intuitively clear but the details might sometimes
		be a bit surprising. So let us look in detail at how it works inside
		on an example of a fairly convoluted scheduling sequence.
		</para>

		<indexterm>
			<primary>queue</primary>
		</indexterm>
		<indexterm>
			<primary>frame</primary>
		</indexterm>
		<indexterm>
			<primary>stack</primary>
		</indexterm>
		<indexterm>
			<primary>draining</primary>
		</indexterm>
		<para>
		A scheduler in the execution unit keeps a stack of queues. Each queue
		is essentially a stack frame, so I'll be using the terms <pre>queue</pre> and
		<pre>frame</pre> interchangeably. The stack always contains at least one
		queue, which is called the outermost stack frame.
		</para>

		<para>
		When the new rowops come from the outside world, they are added with
		<pre>schedule()</pre> to that stack frame. That's what <pre>schedule()</pre> does: always
		adds rowops to the outermost stack frame. If rowops 1, 2 and 3 are
		added, the stack looks like this (the brackets denote a stack frame):
		</para>

<pre>
[1, 2, 3]
</pre>

		<para>
		The unit method <pre>drainFrame()</pre> is then used to run the
		scheduler and process the rowops. It makes the unit call each rowop on
		the innermost frame (which is initially the same as outermost
		frame, since there is only one frame) in order.
		</para>

		<para>
		First it calls the rowop 1. It's removed from the queue, then a new
		frame is pushed onto the stack:
		</para>

<pre>
[ ] ~1
[2, 3]
</pre>

		<para>
		This new frame is the rowop 1's frame, which is marked on the diagram
		by <quote>~1</quote>. The diagram shows the most recently pushed, innermost,
		frame on the top, and the oldest, outermost frame on the bottom. The
		concepts of <quote>innermost</quote> and <quote>outermost</quote>
		come from the nested calls: the most recent call is nested the deepest
		in the middle and is the innermost one.
		</para>

		<para>
		Then the rowop 1 executes. If it
		calls rowop 4, another frame is pushed onto the stack for it:
		</para>

<pre>
[ ] ~4
[ ] ~1
[2, 3]
</pre>

		<para>
		Then the rowop 4 executes. The rowop 4 never gets onto any of the queues.
		The call just pushes a new frame and executes the rowop right away.
		The identity of rowop being processed is kept in the call context. A
		call also involves a direct C++ call on the thread stack, and if any
		Perl code is involved, a Perl call too. Because of this, if you nest
		the calls too deeply, you may run out of the thread stack space and
		get it to crash.
		</para>

		<para>
		After the rowop 4 is finished (not calling any other
		rowops), the innermost empty frame is popped before the execution of
		rowop 1 continues. The queue stack reverts to the previous state.
		</para>

<pre>
[ ] ~1
[2, 3]
</pre>

		<para>
		Suppose then rowop 1 forks rowops 5 and 6. They are appended to the
		innermost frame in the order they are forked.
		</para>

<pre>
[5, 6] ~1
[2, 3]
</pre>

		<para>
		If rowop 1 then calls rowop 7, again a frame is pushed onto the stack
		before it executes:
		</para>

<pre>
[ ] ~7
[5, 6] ~1
[2, 3]
</pre>

		<para>
		The rowops 5 and 6 still don't execute, they keep sitting on the queue
		until the rowop 1 would return.
		After the call of rowop 7 completes, the scheduler stack returns to
		the previous state.
		</para>

		<para>
		Suppose now the execution of rowop 1 completes. But its stack frame can
		not be popped yet, because it is not empty. The scheduler calls
		<pre>drainFrame()</pre> recursively, which picks the next rowop from the innermost
		queue (rowop 5), and calls it, pushing a new stack frame and executing
		the rowop 5 code:
		</para>

<pre>
[ ] ~5
[6] ~1*
[2, 3]
</pre>

		<para>
		The former rowop 1's frame is now marked with <quote>~1*</quote>
		for the ease of tracking, even though it has completed.
		</para>

		<para>
		If rowop 5 forks rowop 8, the stack becomes:
		</para>

<pre>
[8] ~5
[6] ~1*
[2, 3]
</pre>

		<para>
		When the execution of rowop 5 returns, its queue is also not empty. So
		the scheduler starts draining the innermost frame again, and calls rowop 8.
		During its execution the stack is:
		</para>

<pre>
[ ] ~8
[ ] ~5*
[6] ~1*
[2, 3]
</pre>

		<para>
		Suppose the rowop 8 doesn't call or fork anything else and returns. Its
		innermost queue is empty, so the call completes and pops the stack
		frame:
		</para>

<pre>
[ ] ~5*
[6] ~1*
[2, 3]
</pre>

		<para>
		Now the queue of rowop 5 is also empty, so its draining completes and
		pops the drained frame:
		</para>

<pre>
[6] ~1*
[2, 3]
</pre>

		<para>
		The draining of the rowop 1's frame continues by picking the rowop 6
		from the queue and calling it:
		</para>

<pre>
[ ] ~6
[ ] ~1*
[2, 3]
</pre>

		<para>
		Suppose rowop 6 calls <pre>schedule()</pre> of rowop 9. Rowop 9 is then
		added to the outermost queue:
		</para>

<pre>
[ ] ~6
[ ] ~1*
[2, 3, 9]
</pre>

		<para>
		Rowop 6 then returns, its queue is empty, so it's popped and its call completes.
		</para>

<pre>
[ ] ~1*
[2, 3, 9]
</pre>

		<para>
		Now the queue of rowop 1 has become empty, so it's popped from the
		stack and the call of rowop 1 completes:
		</para>

<pre>
[2, 3, 9]
</pre>

		<para>
		The unit method <pre>drainFrame()</pre> keeps running on the outermost
		frame, now taking the rowop 2 and executing it, and so on, until the
		outermost queue becomes empty, and <pre>drainFrame()</pre> returns.
		</para>
	</sect1>

	<sect1 id="sc_sched_loop">
		<title>Loop scheduling</title>

		<indexterm>
			<primary>schedule</primary>
			<secondary>loop</secondary>
		</indexterm>
		<para>
		The easiest and most efficient way to schedule the loops is to do it
		procedurally, something like this:
		</para>

<pre>
foreach my $row (@rowset) {
	$unit->call($lbA->makeRowop(&Triceps::OP_INSERT, $row)); 
}
</pre>

		<para>
		However the labels topologically connected into a loop can come handy
		as well. Some logic may be easier to express this way. Suppose the
		model contains the labels connected in a loop, as in
		<xref linkend="fig_sched_loop" xrefstyle="select: label nopage"/>&xrsp;.
		</para>

		<figure id="fig_sched_loop" >
			<title>Labels forming a loop.</title>
			<xi:include href="file:///FIGS/label-010-loop.xml"/> 
		</figure>

		<para>
		But if handled simple-mindedly, it can use a lot of stack space.
		Suppose some rowop X1 is scheduled for label X, and causes the loop
		to be executed twice, with rowops X1, A2, B3, C4, A5, B6, C7, Y8. If each
		operation is done as a <pre>call()</pre>, the stack grows like this: It starts with
		X1 scheduled.
		</para>

<pre>
[X1]
</pre>

		<para>
		Which then gets executed, with its own execution frame (marked as such
		for clarity):
		</para>

<pre>
[ ] ~X1
[ ]
</pre>

		<para>
		Which then calls A2:
		</para>

<pre>
[ ] ~A2
[ ] ~X1
[ ]
</pre>

		<para>
		By the time the execution comes to Y8, the stack looks like this:
		</para>

<pre>
[ ] ~Y8
[ ] ~C7
[ ] ~B6
[ ] ~A5
[ ] ~C4
[ ] ~B3
[ ] ~A2
[ ] ~X1
[ ]
</pre>

		<para>
		The loop has been converted into recursion, and the whole length of
		execution is the depth of the recursion. If the loop executes a million
		times, the stack will be three million levels deep. Worse yet, it's not
		just the Triceps scheduler stack that grows, it's also the process
		(C++) stack.
		</para>

		<para>
		Would things be better with <pre>fork()</pre> instead of
		<pre>call()</pre> used throughout the loop? It starts the same way:
		</para>

<pre>
[X1]
</pre>

		<para>
		Then X1 executes, gets its own frame and forks A2:
		</para>

<pre>
[A2] ~X1
[ ]
</pre>

		<para>
		Then A2 executes, gets its own frame and forks B3:
		</para>

<pre>
[B3] ~A2
[ ] ~X1*
[ ]
</pre>

		<para>
		Even though X1 has completed, its stack frame stays until all the rowops
		forked in it complete too.
		By the end of the loop the stack picture becomes exactly the same as with
		<pre>call()</pre>. For a while I've thought that optimizing out the empty stack
		frames would solve the problem, but no, that doesn't work: the problem
		is that the C++ process stack keeps growing no matter what. The jump
		back in the loop needs to be placed into an earlier stack frame to
		prevent the stack from growing.
		</para>

		<para>
		One way to do it would be to use the <pre>schedule()</pre> operation in
		C to jump back to A, placing the rowop A5 back onto the outermost
		frame. The scheduler stack at the end of C4 would look like:
		</para>

<pre>
[ ] ~C4
[ ] ~B3
[ ] ~A2
[ ] ~X1
[A5]
</pre>

		<para>
		Then the stack would unwind back to:
		</para>

<pre>
[A5]
</pre>

		<para>
		And the next iteration of the loop will start afresh. The problem here
		is that if X1 wanted to complete the loop and then do something, it
		can't. By the time the second iteration of the loop starts, X1 is
		completely gone. It would be better to be able to enqueue the next
		execution of the loop at the specific point of the stack.
		</para>

		<indexterm>
			<primary>frame mark</primary>
		</indexterm>
		<para>
		Here the concept of the frame mark comes in. A frame mark is a token
		object, completely opaque to the program. It can be used only in two
		operations:
		</para>

		<itemizedlist>
		<listitem>
		<pre>setMark()</pre> remembers the  position in the frame stack, just
		outside the current frame.
		</listitem>
		<listitem>
		<pre>loopAt()</pre> enqueues a rowop at the marked frame.
		</listitem>
		</itemizedlist>

		<para>
		Then the loop wold have its mark object M. The label A will execute
		<pre>setMark(M)</pre>, and the label C will execute <pre>loopAt(M, rowop(A))</pre>. The rest
		of the execution can as well use <pre>call()</pre>.
		</para>

		<para>
		When A2 calls setMark(M), the stack will look like this:
		</para>

<pre>
[ ] ~A2
[ ] ~X1, mark M
[ ]
</pre>

		<para>
		The mark M remembers the frame one outer to the current one. The stack
		at the end of C4, after it has called <pre>loopAt(M, A5)</pre>, is:
		</para>

<pre>
[ ] ~C4
[ ] ~B3
[ ] ~A2
[A5] ~X1, mark M
[ ]
</pre>

		<para>
		The stack then unwinds until A5 starts its execution:
		</para>

<pre>
[ ] ~A5
[ ] ~X1*, mark M
[ ]
</pre>

		<para>
		Each iteration starts with a fresh stack, and the stack depth is
		limited to one iteration. The nested loops can also be properly
		executed.
		</para>

		<para>
		Now, why does the mark is placed on the frame that is one out from the
		current one? After all, this means that X1 can not wait for the
		loop to complete. It has to return before the second iteration of
		the loop can start. And then the rest of the loop will run before
		the control returns to X1's caller. At least the caller of X1 can
		wait for the loop to complete before continuing its execution.
		Why all this trouble? Its the result of a compromise.
		Suppose that it did remember the current frame. Then at
		the end of C4 the stack will be:
		</para>

<pre>
[ ] ~C4
[ ] ~B3
[A5] ~A2, mark M
[ ] ~X1
[ ]
</pre>

		<para>
		The stack will unwind until A5. Which would then have its own frame
		pushed onto the stack, and the code in the label A will call <pre>setMark(M)</pre> 
		again, moving the mark to A5's own frame because it's the topmost frame now:
		</para>

<pre>
[ ] ~A5, mark M
[ ] ~A2*
[ ] ~X1
[ ]
</pre>

		<para>
		So on each iteration of the loop one extra frame will be pushed onto
		the stack, and the mark moved by one level. A loop executing a million
		times will push a million frames, which is bad. Marking the next outer
		frame prevents this. Another option would have been to put the
		mark operation in X, but that would mean that every loop must have a preceding
		label that just marks the frame (well, and potentially could do the
		other initializations too), which seems to be too annoying.
		</para>

		<para>
		It's one problem or the other, and the lesser problem won.
		This is still messy, and I'm still thinking about the ways to improve
		the situation.
		</para>

		<para>
		What happens after the stack unwinds past the mark? The mark gets
		unset. When someone calls <pre>loopAt()</pre> with an unset mark, the rowop is
		enqueued in the outermost frame, having the same effect as schedule<pre>()</pre>.
		</para>

		<para>
		This handling of an unset mark comes handy in case if the loop execution
		takes a pause in the middle. Suppose the label B finds that it can't process
		the rowop B3 until some other data has arrived. What it can do then is remember
		B3 somewhere in the thread state and return. The loop has not completed but
		it can't progress either, so the call unrolls until it becomes empty.
		Since the frame of X1 is popped off the stack, the mark M gets unset. 
		The knowledge that the loop needs to be continued stays remembered
		in the state.
		</para>

		<para>
		After some time that awaited data arrives, as some other rowop. When that
		rowop gets processed, it finds that remembered state with B3 and makes
		it continue, maybe by calling <pre>call(B3)</pre> again. So now the
		logic in B finds all the data it needs and continues with the loop,
		calling C4. C4 will do its job and call <pre>loopAt(M, A5)</pre>.
		But the mark M has been unset a while ago!  Scheduling A5 at the outermost
		frame seems to be a logical thing to do at this point. Then whatever
		current processing will complete and unwind, and the loop will continue
		after it.
		</para>

		<para>
		What if <pre>setMark()</pre> is called when there is only one frame on
		the stack? Then there is no second frame outer to it. The mark will
		simply be left unset.
		</para>

		<para>
		</para>

<pre>
</pre>

<pre>
</pre>

<pre>
</pre>

	</sect1>

</chapter>
