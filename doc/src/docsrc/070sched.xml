<?xml version="1.0" encoding="UTF-8"?>

<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.5CR3//EN"
	"http://www.oasis-open.org/docbook/xml/4.5CR3/docbookx.dtd" [
<!ENTITY % userents SYSTEM "file:///ENTS/user.ent" >
%userents;
]>

<!--
(C) Copyright 2011-2012 Sergey A. Babkin.
This file is a part of Triceps.
See the file COPYRIGHT for the copyright notice and license information
-->

<chapter id="ch_scheduling" xmlns:xi="http://www.w3.org/2001/XInclude">
	<title>Scheduling</title>

	<sect1 id="sc_sched_overview">
		<title>Overview of the scheduling</title>

		<indexterm>
			<primary>scheduling</primary>
		</indexterm>
		<indexterm>
			<primary>model</primary>
		</indexterm>
		<para>
		The scheduling determines, in which order the row operations are
		processed. If there are multiple operations available, which one
		should be processed first?  The scheduler keeps a queue of the operations
		and selects, which one to execute next.  This has a major effect on the
		logic of a CEP model.  
		</para>

		<indexterm>
			<primary>Aleri</primary>
		</indexterm>
		<indexterm>
			<primary>Coral8</primary>
		</indexterm>
		<indexterm>
			<primary>Sybase</primary>
		</indexterm>
		<indexterm>
			<primary>StreamBase</primary>
		</indexterm>
		<para>
		There are multiple approaches to scheduling. Aleri essentially doesn't
		have any, except for the flow control between threads, because each its
		element is a separate thread. Coral8 has an intricate scheduling
		algorithm. Sybase R5 has the same logic as Coral8 inside each thread.
		StreamBase presumably also has some.
		</para>

		<para>
		The scheduling logic in Triceps is different from the other CEP
		systems. The Coral8 logic looks at first like the only reasonable way
		to go, but could not be used in Triceps for three reasons: First, it's a trade
		secret, so it can't be simply reused. If I'd never seen it, that would
		not be an issue but I've worked on it and implemented its version for
		R5. Second, it relies on the properties that the compiler computes from
		the model graph analysis. Triceps has no compiler, and could not do
		this. Third, in reality it simply doesn't work that well. There are
		quite a few cases when the Coral8 scheduler comes up with a strange and
		troublesome execution order.
		</para>

		<para>
		For a while I've hoped that Triceps would need no scheduler at all, and
		everything would be handled by the procedural calls. This has proved to
		have its own limitations, and thus the labels and their scheduling were
		born. The Triceps scheduling still has issues to resolve, but overall
		it still feels much better than the Coral8 one.
		</para>
	</sect1>

	<sect1 id="sc_sched_no_bundling">
		<title>No bundling</title>

		<para>
		The most important principle of Triceps scheduling is: No Bundling.
		Every rowop is for itself. The bundling is what messes up the Coral8
		scheduler the most. 
		</para>

		<para>
		What is a bundle? It's a set of records that go through the execution
		together. If you have a model consisting of two functional elements F1
		and F2 connected in a sequential fashion 
		</para>

<pre>
F1->F2 
</pre>

		<para>
		and a few loose records R1, R2, R3, the
		normal execution order without bundling will be:
		</para>

<pre>
F1(R1), F2(R1), F1(R2), F2(R2), F1(R3), F2(R3)
</pre>

		<para>
		Each row goes through the whole model (a real simple one in this case)
		before the next one is touched. This allows F2 to take into
		accont the state of F1 exactly as it was right after processing
		the same record, without any interventions in between.
		</para>

		<para>
		If the same records are placed in a bundle (R1, R2, R3), the execution
		order will be different:
		</para>

<pre>
F1(R1), F1(R2), F1(R3), F2(R1), F2(R2), F2(R3)
</pre>

		<para>
		The whole bundle goes through F1 before the rows go to F2.
		</para>

		<para>
		That would not be a problem, and even could be occasionally useful, if
		the bundles were always created explicitly. In the reality of Coral8,
		every time a statement produces multiple record from a single one
		(think of a join that picks multiple records from another side), it
		creates a bundle and messes up all the logic after it. Some logic gets
		affected so badly that a few statements in CCL (like ON UPDATE) had to
		be designated as always ignoring the bundles, otherwise they would not
		work at all. At DB I wrote a CCL pattern for breaking up the bundles.
		It's rather heavyweight and thus could not be used all over the place
		but provides a generic solution for the most unpleasant cases.
		</para>

		<para>
		Worse yet, the bundles may get created in Coral8 absolutely
		accidentally: if two records happen to have the same timestamp, for all
		practical purposes they would act as a bundle. In the models that were
		designed without the appropriate guards, this leads to the time-based
		bugs that are hard to catch and debug. Writing these guards correctly
		is hard, and testing them is even harder. 
		</para>

		<para>
		Another issue with bundles is that they make the large queries slower.
		Suppose you do a query from a window that returns a million
		records. All of them will be collected in a bundle, then the
		bundle will be sent to the interface gateway that would build one huge
		protocol packet, which will then be sent to the client, which will
		receive the whole packet and then finally iterate on the records in it.
		Assuming that nothing runs out of memory along the way, it will be a
		long time until the client sees the first record. Very, very
		annoying.
		</para>

		<para>
		Aleri also has its own version of bundles, called transactions, but a
		more smart one. Aleri always relies on the primary keys. The condition
		for a transaction is that it must never contain multiple modification
		for the same primary key. Since there are no execution order guarantees
		between the functional elements, in this respect the transactions work
		in the same way as loose records, only with a more efficient
		communication between threads. Still, if the primary key changes in an
		element (say, an aggregator), the condition does not propagate through
		it. Such elements have to internally collapse the outgoing transactions
		along the new key, adding overhead.
		</para>
	</sect1>

	<sect1 id="sc_sched_basic">
		<title>Basic scheduling in Triceps</title>

		<para>
		In Triceps the scheduling is done by the execution unit, or simply
		<quote>unit</quote> as it's often referred to.
		It provides 3 basic ways of executing of a rowop:
		</para>

		<indexterm>
			<primary>unit</primary>
		</indexterm>
		<indexterm>
			<primary>row operation</primary>
		</indexterm>
		<variablelist>
			<varlistentry>
				<term>Call:</term>
				<listitem>
				<indexterm>
					<primary>call</primary>
				</indexterm>
				<para>
				Execute the label right now, including all the nested calls.
				All of this will be completed after the call returns.
				</para>
				</listitem>
			</varlistentry>
			<varlistentry>
				<term>Fork:</term>
				<listitem>
				<indexterm>
					<primary>fork</primary>
				</indexterm>
				<para>
				Execute the label after the current label returns but
				before anything else is done. Obviously, if multiple labels are
				forked, they will execute in order after the current label
				returns (but before its caller gets the control back).
				This method has looked promising at one point but has currently
				fallen out of favor and will likely be removed in the future.
				</para>
				</listitem>
			</varlistentry>
			<varlistentry>
				<term>Schedule:</term>
				<listitem>
				<indexterm>
					<primary>schedule</primary>
				</indexterm>
				<para>
				Execute the label after everything else is done.
				</para>
				</listitem>
			</varlistentry>
		</variablelist>

		<para>
		This is kind of intuitively clear but the details might sometimes
		be a bit surprising. So let us look in detail at how it works inside
		on an example of a fairly convoluted scheduling sequence.
		</para>

		<indexterm>
			<primary>queue</primary>
		</indexterm>
		<indexterm>
			<primary>frame</primary>
		</indexterm>
		<indexterm>
			<primary>stack</primary>
		</indexterm>
		<indexterm>
			<primary>draining</primary>
		</indexterm>
		<para>
		A scheduler in the execution unit keeps a stack of queues. Each queue
		is essentially a stack frame, so I'll be using the terms <pre>queue</pre> and
		<pre>frame</pre> interchangeably. The stack always contains at least one
		queue, which is called the outermost stack frame.
		</para>

		<para>
		When the new rowops come from the outside world, they are added with
		<pre>schedule()</pre> to that stack frame. That's what <pre>schedule()</pre> does: always
		adds rowops to the outermost stack frame. If rowops 1, 2 and 3 are
		added, the stack looks like this (the brackets denote a stack frame):
		</para>

<pre>
[1, 2, 3]
</pre>

		<para>
		The unit method <pre>drainFrame()</pre> is then used to run the
		scheduler and process the rowops. It makes the unit call each rowop on
		the innermost frame (which is initially the same as outermost
		frame, since there is only one frame) in order.
		</para>

		<para>
		First it calls the rowop 1. It's removed from the queue, then a new
		frame is pushed onto the stack:
		</para>

<pre>
[ ] ~1
[2, 3]
</pre>

		<para>
		This new frame is the rowop 1's frame, which is marked on the diagram
		by <quote>~1</quote>. The diagram shows the most recently pushed, innermost,
		frame on the top, and the oldest, outermost frame on the bottom. The
		concepts of <quote>innermost</quote> and <quote>outermost</quote>
		come from the nested calls: the most recent call is nested the deepest
		in the middle and is the innermost one.
		</para>

		<para>
		Then the rowop 1 executes. If it
		calls rowop 4, another frame is pushed onto the stack for it:
		</para>

<pre>
[ ] ~4
[ ] ~1
[2, 3]
</pre>

		<para>
		Then the rowop 4 executes. The rowop 4 never gets onto any of the queues.
		The call just pushes a new frame and executes the rowop right away.
		The identity of rowop being processed is kept in the call context. A
		call also involves a direct C++ call on the thread stack, and if any
		Perl code is involved, a Perl call too. Because of this, if you nest
		the calls too deeply, you may run out of the thread stack space and
		get it to crash.
		</para>

		<para>
		After the rowop 4 is finished (not calling any other
		rowops), the innermost empty frame is popped before the execution of
		rowop 1 continues. The queue stack reverts to the previous state.
		</para>

<pre>
[ ] ~1
[2, 3]
</pre>

		<para>
		Suppose then rowop 1 forks rowops 5 and 6. They are appended to the
		innermost frame in the order they are forked.
		</para>

<pre>
[5, 6] ~1
[2, 3]
</pre>

		<para>
		If rowop 1 then calls rowop 7, again a frame is pushed onto the stack
		before it executes:
		</para>

<pre>
[ ] ~7
[5, 6] ~1
[2, 3]
</pre>

		<para>
		The rowops 5 and 6 still don't execute, they keep sitting on the queue
		until the rowop 1 would return.
		After the call of rowop 7 completes, the scheduler stack returns to
		the previous state.
		</para>

		<para>
		Suppose now the execution of rowop 1 completes. But its stack frame can
		not be popped yet, because it is not empty. The scheduler calls
		<pre>drainFrame()</pre> recursively, which picks the next rowop from the innermost
		queue (rowop 5), and calls it, pushing a new stack frame and executing
		the rowop 5 code:
		</para>

<pre>
[ ] ~5
[6] ~1*
[2, 3]
</pre>

		<para>
		The former rowop 1's frame is now marked with <quote>~1*</quote>
		for the ease of tracking, even though it has completed.
		</para>

		<para>
		If rowop 5 forks rowop 8, the stack becomes:
		</para>

<pre>
[8] ~5
[6] ~1*
[2, 3]
</pre>

		<para>
		When the execution of rowop 5 returns, its queue is also not empty. So
		the scheduler starts draining the innermost frame again, and calls rowop 8.
		During its execution the stack is:
		</para>

<pre>
[ ] ~8
[ ] ~5*
[6] ~1*
[2, 3]
</pre>

		<para>
		Suppose the rowop 8 doesn't call or fork anything else and returns. Its
		innermost queue is empty, so the call completes and pops the stack
		frame:
		</para>

<pre>
[ ] ~5*
[6] ~1*
[2, 3]
</pre>

		<para>
		Now the queue of rowop 5 is also empty, so its draining completes and
		pops the drained frame:
		</para>

<pre>
[6] ~1*
[2, 3]
</pre>

		<para>
		The draining of the rowop 1's frame continues by picking the rowop 6
		from the queue and calling it:
		</para>

<pre>
[ ] ~6
[ ] ~1*
[2, 3]
</pre>

		<para>
		Suppose rowop 6 calls <pre>schedule()</pre> of rowop 9. Rowop 9 is then
		added to the outermost queue:
		</para>

<pre>
[ ] ~6
[ ] ~1*
[2, 3, 9]
</pre>

		<para>
		Rowop 6 then returns, its queue is empty, so it's popped and its call completes.
		</para>

<pre>
[ ] ~1*
[2, 3, 9]
</pre>

		<para>
		Now the queue of rowop 1 has become empty, so it's popped from the
		stack and the call of rowop 1 completes:
		</para>

<pre>
[2, 3, 9]
</pre>

		<para>
		The unit method <pre>drainFrame()</pre> keeps running on the outermost
		frame, now taking the rowop 2 and executing it, and so on, until the
		outermost queue becomes empty, and <pre>drainFrame()</pre> returns.
		</para>
	</sect1>

	<sect1 id="sc_sched_loop">
		<title>Loop scheduling</title>

		<indexterm>
			<primary>schedule</primary>
			<secondary>loop</secondary>
		</indexterm>
		<para>
		The easiest and most efficient way to schedule the loops is to do it
		procedurally, something like this:
		</para>

<pre>
foreach my $row (@rowset) {
	$unit->call($lbA->makeRowop(&Triceps::OP_INSERT, $row)); 
}
</pre>

		<para>
		However the labels topologically connected into a loop can come handy
		as well. Some logic may be easier to express this way. Suppose the
		model contains the labels connected in a loop, as in
		<xref linkend="fig_sched_loop" xrefstyle="select: label nopage"/>&xrsp;.
		</para>

		<figure id="fig_sched_loop" >
			<title>Labels forming a loop.</title>
			<xi:include href="file:///FIGS/label-010-loop.xml"/> 
		</figure>

		<para>
		But if handled simple-mindedly, it can use a lot of stack space.
		Suppose some rowop X1 is scheduled for label X, and causes the loop
		to be executed twice, with rowops X1, A2, B3, C4, A5, B6, C7, Y8. If each
		operation is done as a <pre>call()</pre>, the stack grows like this: It starts with
		X1 scheduled.
		</para>

<pre>
[X1]
</pre>

		<para>
		Which then gets executed, with its own execution frame (marked as such
		for clarity):
		</para>

<pre>
[ ] ~X1
[ ]
</pre>

		<para>
		Which then calls A2:
		</para>

<pre>
[ ] ~A2
[ ] ~X1
[ ]
</pre>

		<para>
		By the time the execution comes to Y8, the stack looks like this:
		</para>

<pre>
[ ] ~Y8
[ ] ~C7
[ ] ~B6
[ ] ~A5
[ ] ~C4
[ ] ~B3
[ ] ~A2
[ ] ~X1
[ ]
</pre>

		<para>
		The loop has been converted into recursion, and the whole length of
		execution is the depth of the recursion. If the loop executes a million
		times, the stack will be three million levels deep. Worse yet, it's not
		just the Triceps scheduler stack that grows, it's also the process
		(C++) stack.
		</para>

		<para>
		Would things be better with <pre>fork()</pre> instead of
		<pre>call()</pre> used throughout the loop? It starts the same way:
		</para>

<pre>
[X1]
</pre>

		<para>
		Then X1 executes, gets its own frame and forks A2:
		</para>

<pre>
[A2] ~X1
[ ]
</pre>

		<para>
		Then A2 executes, gets its own frame and forks B3:
		</para>

<pre>
[B3] ~A2
[ ] ~X1*
[ ]
</pre>

		<para>
		Even though X1 has completed, its stack frame stays until all the rowops
		forked in it complete too.
		By the end of the loop the stack picture becomes exactly the same as with
		<pre>call()</pre>. For a while I've thought that optimizing out the empty stack
		frames would solve the problem, but no, that doesn't work: the problem
		is that the C++ process stack keeps growing no matter what. The jump
		back in the loop needs to be placed into an earlier stack frame to
		prevent the stack from growing.
		</para>

		<para>
		One way to do it would be to use the <pre>schedule()</pre> operation in
		C to jump back to A, placing the rowop A5 back onto the outermost
		frame. The scheduler stack at the end of C4 would look like:
		</para>

<pre>
[ ] ~C4
[ ] ~B3
[ ] ~A2
[ ] ~X1
[A5]
</pre>

		<para>
		Then the stack would unwind back to:
		</para>

<pre>
[A5]
</pre>

		<para>
		And the next iteration of the loop will start afresh. The problem here
		is that if X1 wanted to complete the loop and then do something, it
		can't. By the time the second iteration of the loop starts, X1 is
		completely gone. It would be better to be able to enqueue the next
		execution of the loop at the specific point of the stack.
		</para>

		<indexterm>
			<primary>frame mark</primary>
		</indexterm>
		<para>
		Here the concept of the frame mark comes in. A frame mark is a token
		object, completely opaque to the program. It can be used only in two
		operations:
		</para>

		<itemizedlist>
		<listitem>
		<pre>setMark()</pre> remembers the  position in the frame stack, just
		outside the current frame.
		</listitem>
		<listitem>
		<pre>loopAt()</pre> enqueues a rowop at the marked frame.
		</listitem>
		</itemizedlist>

		<para>
		Then the loop wold have its mark object M. The label A will execute
		<pre>setMark(M)</pre>, and the label C will execute <pre>loopAt(M, rowop(A))</pre>. The rest
		of the execution can as well use <pre>call()</pre>, as shown in
		<xref linkend="fig_sched_loop" xrefstyle="select: label nopage"/>&xrsp;.
		</para>

		<figure id="fig_sched_mark" >
			<title>Proper calls in a loop.</title>
			<xi:include href="file:///FIGS/label-011-mark.xml"/> 
		</figure>

		<para>
		When A2 calls setMark(M), the stack will look like this:
		</para>

<pre>
[ ] ~A2
[ ] ~X1, mark M
[ ]
</pre>

		<para>
		The mark M remembers the frame one outer to the current one. The stack
		at the end of C4, after it has called <pre>loopAt(M, A5)</pre>, is:
		</para>

<pre>
[ ] ~C4
[ ] ~B3
[ ] ~A2
[A5] ~X1, mark M
[ ]
</pre>

		<para>
		The stack then unwinds until A5 starts its execution:
		</para>

<pre>
[ ] ~A5
[ ] ~X1*, mark M
[ ]
</pre>

		<para>
		Each iteration starts with a fresh stack, and the stack depth is
		limited to one iteration. The nested loops can also be properly
		executed.
		</para>

		<para>
		Now, why does the mark get placed on the frame that is one out from the
		current one? After all, this means that X1 can not wait for the
		loop to complete. It has to return before the second iteration of
		the loop can start. And then the rest of the loop will run before
		the control returns to X1's caller. At least the caller of X1 can
		wait for the loop to complete before continuing its execution.
		Why all this trouble? Its the result of a compromise.
		Suppose that it did remember the current frame. Then at
		the end of C4 the stack will be:
		</para>

<pre>
[ ] ~C4
[ ] ~B3
[A5] ~A2, mark M
[ ] ~X1
[ ]
</pre>

		<para>
		The stack will unwind until A5. Which would then have its own frame
		pushed onto the stack, and the code in the label A will call <pre>setMark(M)</pre> 
		again, moving the mark to A5's own frame because it's the topmost frame now:
		</para>

<pre>
[ ] ~A5, mark M
[ ] ~A2*
[ ] ~X1
[ ]
</pre>

		<para>
		So on each iteration of the loop one extra frame will be pushed onto
		the stack, and the mark moved by one level. A loop executing a million
		times will push a million frames, which is bad. Marking the next outer
		frame prevents this. Another option would have been to put the
		mark operation in X, but that would mean that every loop must have a preceding
		label that just marks the frame (well, and potentially could do the
		other initializations too), which seems to be too annoying.
		</para>

		<para>
		It's one problem or the other, and the lesser problem won.
		This is still messy, and I'm still thinking about the ways to improve
		the situation.
		</para>

		<para>
		What happens after the stack unwinds past the mark? The mark gets
		unset. When someone calls <pre>loopAt()</pre> with an unset mark, the rowop is
		enqueued in the outermost frame, having the same effect as schedule<pre>()</pre>.
		</para>

		<para>
		This handling of an unset mark comes handy in case if the loop execution
		takes a pause in the middle. Suppose the label B finds that it can't process
		the rowop B3 until some other data has arrived. What it can do then is remember
		B3 somewhere in the thread state and return. The loop has not completed but
		it can't progress either, so the call unrolls until it becomes empty.
		Since the frame of X1 is popped off the stack, the mark M gets unset. 
		The knowledge that the loop needs to be continued stays remembered
		in the state.
		</para>

		<para>
		After some time that awaited data arrives, as some other rowop. When that
		rowop gets processed, it finds that remembered state with B3 and makes
		it continue, maybe by calling <pre>call(B3)</pre> again. So now the
		logic in B finds all the data it needs and continues with the loop,
		calling C4. C4 will do its job and call <pre>loopAt(M, A5)</pre>.
		But the mark M has been unset a while ago!  Scheduling A5 at the outermost
		frame seems to be a logical thing to do at this point. Then whatever
		current processing will complete and unwind, and the loop will continue
		after it.
		</para>

		<para>
		What if <pre>setMark()</pre> is called when there is only one frame on
		the stack? Then there is no second frame outer to it. The mark will
		simply be left unset.
		</para>
	</sect1>

	<sect1 id="sc_sched_unit">
		<title>Execution unit</title>

		<para>
		After discussing the principles of scheduling in Triceps, let's get
		down to the nuts and bolts.
		</para>

		<indexterm>
			<primary>unit</primary>
		</indexterm>
		<para>
		A unit is created as:
		</para>

<pre>
$myUnit = Triceps::Unit->new("name") or confess "$!";
</pre>

		<para>
		The name argument is as usual used for later debugging, and by
		convention should be the same as the name of the unit variable
		(<quote>myUnit</quote> in this case). The name can also be changed later:
		</para>

<pre>
$myUnit->setName("newName");
</pre>

		<para>
		It returns no value. Though in practice there is no good reason for changing names,
		and this call will likely be removed in the future. The name can be
		read back:
		</para>

<pre>
$name = $myUnit->getName();
</pre>

		<para>
		Also, as usual, the variable $myName here contains a reference to the
		actual unit object, and two references can be compared for whether they
		refer to the same object:
		</para>

<pre>
$result = $unit1->same($unit2);
</pre>

		<para>
		A unit also keeps an empty row type (one with no fields), primarily for the
		creation of the clearing labels, but you can use it for any other purposes
		too. You can get it with the method:
		</para>

<pre>
$rt = $unit->getEmptyRowType();
</pre>

		<para>
		Each unit has its own instance of an empty row type. Its purely for
		the conveniece of memory management, they are all equivalent.
		</para>

		<para>
		The rowops are enqueued with the calls:
		</para>

<pre>
$unit->call($rowop, ...);
$unit->fork($rowop, ...);
$unit->schedule($rowop, ...); 
</pre>

		<indexterm>
			<primary>enqueue</primary>
		</indexterm>
		<para>
		<quote>Enqueued</quote> is an ugly word but since I've already used the
		word <quote>schedule</quote> for a specific purpose, I needed another word to name
		all these operations together. Hence <quote>enqueue</quote>.
		</para>

		<para>
		The <quote>...</quote> shows that multiple rowops may be passed as arguments.
		So the real signature of these methods is:
		</para>

<pre>
$unit->call(@rowops);
$unit->fork(@rowops);
$unit->schedule(@rowops); 
</pre>

		<indexterm>
			<primary>error handling</primary>
		</indexterm>
		<indexterm>
			<primary>tray</primary>
		</indexterm>
		<para>
		But this way it loos more confusing. 
		Calling these functions with multiple arguments produces the same
		result as doing multiple calls with one argument at a time. Not only
		rowops but also <i>trays</i> (to be discussed later) of rowops can be
		used as arguments.
		</para>

		<para>
		These methods are among those
		that use the new error handling, that makes the operation to confess
		on any fatal errors. So there is no need to check their results with
		<quote><pre>or confess</pre></quote>.
		</para>

		<para>
		Also there is a call that selects the enqueueing mode by argument:
		</para>

<pre>
$unit->enqueque($mode, @rowops);
</pre>

		<para>
		The calling rules are exactly the same for the other enqueueing methods,
		may have multiple rowops or trays as arguments, no need to check the result.
		The <pre>$mode</pre> argument is one of:
		</para>

		<indexterm>
			<primary>constants</primary>
		</indexterm>
		<itemizedlist>
		<listitem>
		<pre>&Triceps::EM_CALL</pre> or <pre>"EM_CALL"</pre>
		</listitem>
		<listitem>
		<pre>&Triceps::EM_FORK</pre> or <pre>"EM_FORK"</pre>
		</listitem>
		<listitem>
		<pre>&Triceps::EM_SCHEDULE</pre> or <pre>"EM_SCHEDULE"</pre>
		</listitem>
		</itemizedlist>

		<para>
		As usual, there are calls to convert between the integer constant and
		string representations:
		</para>

<pre>
$string = &Triceps::emString($value);
$value = &Triceps::stringEm($string);
</pre>

		<para>
		And as usual, if the value can not be translated, they return <pre>undef</pre>.
		</para>

		<para>
		The frame marks for looping are created as their own class:
		</para>

		<indexterm>
			<primary>frame mark</primary>
		</indexterm>
<pre>
$mark = Triceps::FrameMark->new("name") or confess "$!";
</pre>

		<para>
		The name can be obtained back from the mark:
		</para>

<pre>
$name = $mark->getName();
</pre>

		<para>
		Other than that, the frame marks are completely opaque, and can be used
		only for the loop scheduling. Not even the <pre>same()</pre> method is supported
		for them at the moment, though it probably will be in the future. The
		mark gets set and used as:
		</para>

<pre>
$unit->setMark($mark);
$unit->loopAt($mark, @rowops);
</pre>

		<para>
		The rowop arguments of the <pre>loopAt()</pre> are the same as for the
		other enqueueing functions, and as for other functions they may happen
		to be trays. These methods also use the new error handling scheme, and
		will confess on errors. No need to check the results.
		</para>

		<para>
		There also are the convenience methods that create the rowops
		from the field values and immediately enqueue them:
		</para>

<pre>
$unit->makeHashCall($label, $opcode, 
	$fieldName => $fieldValue, ...);
$unit->makeArrayCall($label, $opcode, @fieldValues);

$unit->makeHashSchedule($label, $opcode, 
	$fieldName => $fieldValue, ...);
$unit->makeArraySchedule($label, $opcode, @fieldValues);

$unit->makeHashLoopAt($mark, $label, $opcode, 
	$fieldName => $fieldValue, ...);
$unit->makeArrayLoopAt($mark, $label, $opcode, @fieldValues);
</pre>

		<para>
		These are essentially the shorter ways to make the rowops and enqueue
		them without the three-deep calls. Only the methods for the most 
		frequently used enqueueing modes are provided, not for all of them.
		All these methods also confess on errors.
		</para>

		<para>
		The methods for creation of labels have been already discussed in
		<xref linkend="sc_Label_construction" xrefstyle="select: label quotedtitle pageabbrev"/>&xrsp;.
		Here is their recap along with the similar methods for creation of
		tables and trays that will be discussed later:
		</para>

<pre>
$label = $unit->makeDummyLabel($rowType, "name") 
	or confess "$!";

$label = $unit->makeLabel($rowType, "name",
	$clearSub, $execSub, @args) or confess "$!";

$label = $unit->makeClearingLabel("name", @args);

$table = $unit->makeTable($tableType, $enqMode, "name") 
	or confess "$!";

$tray = $unit->makeTray(@rowops) or confess "$!"; 
</pre>

		<para>
		Of them <pre>makeClearingLabel()</pre> uses the new error handling convention,
		confessing by itself, and the rest return an undef on errors that
		has to be checked. It's actually real difficult to make 
		<pre>makeClearingLabel()</pre> fail, only by corrupting some of the Triceps
		internal variables, and it was a late additiion, so going straight
		with the new convention for it made sense.
		</para>

		<indexterm>
			<primary>memory management</primary>
		</indexterm>
		<para>
		A special thing about the labels is that when a unit creates
		a label, it keeps a reference to it, for clearing. A label keeps a pointer
		back to the unit but not a reference (if you call <pre>getUnit()</pre>
		on a label, the returned value becomes a reference). For a table
		or a tray, the unit doesn't keep a reference to them. Instead,
		they keep a reference to the unit. With the tables, it can get
		pretty involved: A table has labels associated with it.
		When a table is created, it also creates these labels.
		The unit keeps references of these labels. The table also
		keeps references of these labels. The table keeps a reference
		of the unit. The labels (they are at the &Cpp; level, not Perl level)
		have pointers to the unit and the
		table but not references, to avoid the reference cycles.
		</para>

		<para>
		See more on the memory management and label clearing in the
		<xref linkend="ch_memory" xrefstyle="select: label quotedtitle pageabbrev"/>&xrsp;.
		</para>

		<para>
		The unit can be checked for the emptiness of its queues:
		</para>

<pre>
$result = $unit->empty();
</pre>

		<para>
		The functions for execution from the queues are:
		</para>

<pre>
$unit->callNext();
$unit->drainFrame();
</pre>

		<para>
		<pre>callNext()</pre> takes one label from the top (innermost) stack frame queue and calls it.
		If the innermost frame happens to be empty, it does nothing. 
		<pre>drainFrame()</pre> calls the rowops from the top stack frame until it becomes
		empty. This includes any rowops that may be created and enqueued as
		part of the execution of the previous rowops. But it doesn't pop the
		frame from the stack.  And of course the method
		<pre>call()</pre> causes the argument rowops to be executed immediately, without
		even being technically enqueued.
		</para>
	</sect1>

	<sect1 id="sc_sched_unwind">
		<title>Error handling during the execution</title>

		<indexterm>
			<primary>error handling</primary>
		</indexterm>
		<para>
		When the labels execute, they may produce errors in one of two ways:
		</para>

		<itemizedlist>
		<listitem>
		The Perl code in the label might die.
		</listitem>
		<listitem>
		The call topology might violate the rules. 
		</listitem>
		</itemizedlist>

		<para>
		The rules are basically that you can't make the recursive calls.
		A label may not make calls directly or through other labels to itself.
		The idea is to catch the call sequences that are likely to go into 
		the deep recursion and overflow the stack. It catches them early,
		on the first attempt of recursion. If you need to do the recursion,
		use <pre>schedule()</pre> or <pre>loopAt()</pre>. That way you 
		avoid overrunning the stack.
		</para>

		<indexterm>
			<primary>XS</primary>
		</indexterm>
		<indexterm>
			<primary>draining</primary>
		</indexterm>
		<indexterm>
			<primary>stack</primary>
			<secondary>unwinding</secondary>
		</indexterm>
		<para>
		Whichever way the error is detected, it causes the Triceps call
		stack to be unwound. The Perl error messages from <pre>die</pre> or <pre>confess</pre>
		and the &Cpp; tracing of rowop calls and label chainings get
		combined into a common stack trace. When the code gets back to
		Perl, the XS code triggers a <pre>confess</pre>. If that happens to be in the
		handler of another rowop, it continues the Triceps hybrid stack
		unwinding. If not caught by <pre>eval</pre>, it keeps going to the topmost
		<pre>call()</pre> or <pre>drainFrame()</pre> and causes the whole program to die.
		Which is a reasonable reaction most of the time.
		</para>

		<para>
		Remember, the root cause is a serious error that is likely to leave the
		model in an inconsistent state, and it should usually be considered
		as fatal. If you want to catch the errors, nip them in the bud
		by wrapping your Perl code in <pre>eval</pre>. Then you can handle
		the errors before thay have a chance to propagate.
		</para>

		<para>
		An interesting question is, what happens to the rowops that were
		in the Triceps stack frames when the stack gets unwound? They
		get thrown away. The memory gets collected thanks to the reference
		counting, but the rowops and their sequence order get thrown away.
		The reason is basically that there may be no catching of the
		errors until unwinding to the <pre>drainFrame()</pre>. The choice is to either
		throw away everything after the first error or keep trying to
		execute the following rowops, collecting the errors. And that
		might become a lot of errors. I've taken the choice of stopping
		as early as possible, because the state of the model will probably
		be corrupted anyway and nothing but garbage would be coming out
		(if anything would be coming at all and not be stuck in an
		endless loop).
		</para>
	</sect1>

	<sect1 id="sc_sched_mainloop">
		<title>The main loop</title>

		<indexterm>
			<primary>main loop</primary>
		</indexterm>
		<para>
		The execution unit doesn't magically process the data by itself.
		The data needs to be pushed into it, and the unit has to be told
		to process it. There has to be some internal code to drive it,
		that would continuously read the data, schedule, drain.
		</para>

		<para>
		A typical way of processing the incoming rowops in a loop is:
		</para>

<pre>
$stop = 0; 
while (!$stop) {
	$rowop = &readRowop(); # some user-defined function
	$unit->call($rowop);
	$unit->drainFrame();
} 
</pre>

		<para>
		The rowops coming from the outside get executed as they are received,
		and then any rows left over from them get handled by <pre>drainFrame()</pre>
		before the next incoming rowop is read.
		Some of the executed rowops may set <pre>$stop</pre>, and the main loop
		will exit. 
		</para>

		<para>
		There is also another version of the main loop that has been more
		historic:
		</para>

<pre>
$stop = 0; 
while (!$stop) {
	$rowop = &readRowop(); # some user-defined function
	$unit->schedule($rowop);
	$unit->drainFrame();
} 
</pre>

		<para>
		It uses <pre>schedule()</pre> instead of <pre>call()</pre> for the rowop.
		As long as only one rowop is scheduled before draining the frame, both
		versions work equally well. But if you schedule multiple rowops before
		draining the frame, you can introduce a subtle unpredictability in the
		execution order. It is described in detail in
		<xref linkend="sc_sched_issues" xrefstyle="select: label quotedtitle pageabbrev"/>&xrsp;.
		Actually, you can have the same problem if you don't drain the frame
		after each top-level <pre>call()</pre> too. But mentally <pre>call()</pre> kind of reminds
		better to feed the rowops one at a time, and also is slightly more
		efficient, so now I prefer the version with it.
		</para>

		<para>
		Many of the examples in this manual use the main loop along the
		following lines (with variations, to fit the examples, and as the
		main loop was refined over time):
		</para>

<pre>
while(&readLine) {
	chomp;
	my @data = split(/,/); # starts with a command, then string opcode
	my $type = shift @data;
	if ($type eq "lbCur") {
		$unit->makeArrayCall($lbCur, @data);
	} elsif ($type eq "lbPos") {
		$unit->makeArrayCall($lbPos, @data);
	}
	$unit->drainFrame();
}
</pre>

		<para>
		It reads the CSV (Comma-Separated Values) data from stdin,
		with the label name in the first column, the opcode in the
		second, and the data fields in the rest. Then dispatches
		according to the label. Doing a <pre>call()</pre> instead 
		of <pre>schedule()</pre> works just as well, and the following
		<pre>drainFrame()</pre> takes care of any rowops scheduled
		from the call.
		</para>

		<para>
		Many variations are possible. It can be generalized to look up
		the labels from the hash:
		</para>

<pre>
while(&readLine) {
	chomp;
	my @data = split(/,/); # starts with a command, then string opcode
	my $type = shift @data;
	$unit->makeArrayCall($labels{$type}, @data);
	$unit->drainFrame();
}
</pre>

		<para>
		Or call the procedural functions for some types:
		</para>

<pre>
while(&readLine) {
	chomp;
	my @data = split(/,/); # starts with a command, then string opcode
	my $type = shift @data;
	if ($type eq "lbCur") {
		$unit->makeArrayCall($lbCur, @data);
	} elsif ($type eq "lbPos") {
		$unit->makeArrayCall($lbPos, @data);
	} elsif ($type eq "clear") { # clear the previous day
		&clearByDate($tPosition, @data);
	}
	$unit->drainFrame();
}
</pre>

		<para>
		Though none of these small examples are production-ready. At the
		very least, their parsing of the CSV data is primitive. It
		can't handle the quoting properly and can't parse the data
		with commas in it.
		</para>

		<para>
		A better ready way to parse the data will be provided in the future.
		For now, make your own.
		</para>
	</sect1>

	<sect1 id="sc_sched_issues">
		<title>Issues with the Triceps scheduling</title>

		<para>
		As much as I like it, the Triceps scheduling is not perfect, and has
		some open issues at the moment.  Some of them have been already
		mentioned in the description of the loop scheduling: it's a bit
		confusing that the frame mark is placed on the next outer scheduling
		stack frame and not on the current one. This leads to the interesting
		effects in execution order.
		</para>

		<para>
		The other one has been mentioned in the main loop discussion:
		the <pre>schedule()</pre> call, when used from inside the scheduled code,
		may introduce unpredictability in the execution order. It puts the rowop
		after the last rowop in the outermost stack frame. But the outermost
		stack frame may contain a whole queue of rowops that come from the outside.
		This means that the exact order of execution will depend on the timing
		of the rowops arriving from outside. 
		</para>

		<para>
		Let me demonstrate it with an example. Suppose the main loop tries to
		optimize by collecting and schedulng as many incoming rowops as it can
		before running them:
		</para>

		<indexterm>
			<primary>main loop</primary>
		</indexterm>
<pre>
$stop = 0; 
while (!$stop) {
	&waitForIncomingData(); # some user-defined function
	while ($rowop = &readRowop()) { # some user-defined function
		$unit->schedule($rowop);
	}
	$unit->drainFrame();
} 
</pre>

		<para>
		Suppose the rowops A, B, C, D are being received from the outside.
		When the rowop A executes, it schedules the rowop E. Then depending
		on the timing of the packets in the network, the call sequence may
		be
		</para>

<pre>
schedule(A)
drainFrame()
schedule(B)
drainFrame()
schedule(C)
drainFrame()
schedule(D)
drainFrame()
</pre>

		<para>
		or
		</para>

<pre>
schedule(A)
schedule(B)
drainFrame()
schedule(C)
schedule(D)
drainFrame()
</pre>

		<para>
		or
		</para>

<pre>
schedule(A)
schedule(B)
schedule(C)
schedule(D)
drainFrame()
</pre>

		<para>
		or a few other combinations. In the first case the actual execution order
		will be A, E, B, C, D. That's because when A schedules E, E will be picked
		up and executed by the first following frame drain. In the second case the
		execution order will be A, B, E, C, D. Here when E gets scheduled, B is 
		already on the queue in front of it. In the third case the order will
		be A, B, C, D, E. And it will fluctuate at random between the runs.
		</para>

		<para>
		If the repeatable execution order is important (and usually it is), 
		the solution if to feed the rowops one by one and drain the frame
		right afterwards. Then the execution order will always be A, E, B, C, D.
		When feeding one by one, <pre>call()</pre> can be used instead of <pre>schedule()</pre>,
		and even slightly more efficient. Just don't forget to drain the frame
		after each call.
		</para>

		<para>
		The same issue happens with the loops that have been temporarily
		stopped and then resumed on arrival of more data from outside. The mark
		of such a loop will be unset when the loop continues, and looping at
		this mark will be equivalent to <pre>schedule()</pre>, having the same
		repeatability problem. The same solution works for this issue too.
		</para>

		<para>
		The call <pre>fork()</pre> is not exactly useful. It was created when I've
		thought that it's the solution to the problem of the loops. Which it
		has turned out to not solve, and another solution had to be devised.
		Now it really doesn't have much use, and will probably be removed in
		the future.
		</para>

		<para>
		I have a few ideas for better solutions of these issues, but they will
		need a bit more experimentation. Just keep in mind that the scheduling
		will be refined in the future. It will still have the same general
		shape but differ in detail.
		</para>

		<para>
		</para>

		<para>
		</para>

		<para>
		</para>

<pre>
</pre>

<pre>
</pre>

	</sect1>

</chapter>
