<?xml version="1.0" encoding="UTF-8"?>

<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.5CR3//EN"
	"http://www.oasis-open.org/docbook/xml/4.5CR3/docbookx.dtd" [
<!ENTITY % userents SYSTEM "file:///ENTS/user.ent" >
%userents;
]>

<!--
(C) Copyright 2011-2013 Sergey A. Babkin.
This file is a part of Triceps.
See the file COPYRIGHT for the copyright notice and license information
-->

<chapter id="ch_strf" xmlns:xi="http://www.w3.org/2001/XInclude">
	<title>Streaming functions</title>

	<sect1 id="sc_strf_intro">
		<title>Introduction to streaming functions</title>

		<indexterm>
			<primary>streaming function</primary>
		</indexterm>
		<indexterm>
			<primary>function</primary>
		</indexterm>
		<indexterm>
			<primary>macro</primary>
		</indexterm>

		<para>
		The streaming functions are a cool and advanced
		concept. I've never seen it anywhere before, and for all I know I have
		invented it.
		</para>

		<para>
		First let's look at the differences between the common functions and
		macros (or templates and such), shown in
		<xref linkend="fig_strf_fmac" xrefstyle="select: label nopage"/>&xrsp;.
		</para>

		<figure id="fig_strf_fmac" >
			<title>The difference between the function and macro calls.</title>
			<xi:include href="file:///FIGS/func-010-fmac.xml"/> 
		</figure>

		<para>
		What happens during a function call? Some code
		(marked with the light bluish color) is happily zooming along when it
		decides to call a function. It prepares some arguments and jumps to the
		function code (reddish). The function executes, computes its result and
		jumps back to the point right after it has been called from. Then the
		original code continues from there (the slightly darker bluish color).
		</para>

		<para>
		What happens during a macro (or template) invocation? It starts with
		some code zooming along in the same way, however when the macro call
		time comes, it prepares the arguments and then does nothing. It gets
		away with it because the compiler has done the work: it has placed the
		macro code right where it's called, so there is no need for jumps.
		After the macro is done, again it does nothing: the compiler has placed
		the next code to execute right after it, so it just continues on its
		way.
		</para>

		<para>
		So far it's pretty equivalent. An interesting difference happens when
		the function or macro is called from more than one place. With a macro,
		another copy of the macro is created, inserted between its call and
		return points. That's why in the figure the macro is shown twice. But
		with the function, the same function code is executed every time, and then returns
		back to the caller. That's why in the figure there are two function
		callers with their paths through the same function. But how does the
		function know, where should it jump on return? The caller tells it by
		pushing the return address onto the stack. When the function is done,
		it pops this address from the stack and jumps there.
		</para>

		<para>
		Still, it looks all the same. A macro call is a bit more efficient,
		except when a large complex macro is called from many places, then it
		becomes more efficient as a function. However there is another
		difference if the function or macro holds some context (say, a static
		variable): each invocation of the macro will get its own context but
		all the function calls will share the same context. The only way to
		share the context with a macro is to pass some global context as its
		argument (or you can use a separately defined global variable if you're
		willing to dispense with some strict modularity).
		</para>

		<indexterm>
			<primary>Sybase</primary>
		</indexterm>
		<indexterm>
			<primary>StreamBase</primary>
		</indexterm>
		<indexterm>
			<primary>template</primary>
		</indexterm>

		<para>
		Now let's switch to the CEP world. The Sybase or StreamBase modules are
		essentially macros, and so are the Triceps templates. When such a macro
		gets instantiated, a whole new copy of it gets created with its
		tables/windows and streams/labels. Its input and output streams/labels
		get all connected in a fixed way. The limitation is that if the macro
		contains any tables, each instantiation gets another copy of them. Well, in
		Triceps you can use a table as an argument to a template. In the other
		systems I think you still can't, so if you want to work with a common
		table in a module, you have to make up the query-response patterns,
		like the one described in
		<xref linkend="sc_template_intro" xrefstyle="select: label quotedtitle pageabbrev"/>&xrsp;.
		</para>

		<para>
		In a query-response pattern there is some common sub-model, with a
		stream (in Triceps terms, a label, but here we're talking the other
		systems) for the queries to come in and a stream for the results to
		come out (both sides might have not only one but multiple streams).
		There are multiple inputs connected, from all the request sources, and
		the outputs are connected back to all the request sources. All the
		request sources (i.e. callers) get back the whole output of the
		pattern, so they need to identify, what output came from their input,
		and ignore the rest. They do this by adding the unique ids to their
		queries, and filter the results. In the end, it looks <i>almost</i>
		like a function but with much pain involved.
		</para>

		<para>
		To make it look quite like a function, one thing is needed: the
		selective connection of the result streams (or, returning to the
		Triceps terminology, labels) to the caller. Connect the output labels,
		send some input, have it processed and send the result through the
		connection, disconnect the output labels. And what you get is a
		streaming function. It's very much like a common function but working
		on the streaming data arguments and results.
		</para>

		<para>
		The 
		<xref linkend="fig_strf_query" xrefstyle="select: label nopage"/>&xrsp;
		highlights the similarity and differences between the
		query patterns and the streaming functions.
		</para>

		<figure id="fig_strf_query" >
			<title>The query patterns and streaming functions.</title>
			<xi:include href="file:///FIGS/func-020-query.xml"/> 
		</figure>

		<para>
		The thick lines show where the data goes
		during one concrete call. The thin lines show the connections that do
		exist but without the data going through them at the moment (they will
		be used during the other calls, from these other callers). The dashed
		thin line shows the connection that doesn't exist at the moment. It
		will be created when needed (and at that time the thick arrow from the
		streaming function to what is now the current return would disappear).
		</para>

		<para>
		The particular beauty of the streaming functions for Triceps is that
		the other callers don't even need to exist yet. They can be created
		and connected dynamically, do their job, call the function, use its
		result, and then be disposed of. The calling side in Triceps doesn't
		have to be streaming either: it could as well be procedural.  
		</para>
	</sect1>

	<sect1 id="sc_strf_collapse">
		<title>Streaming functions by example, another version of Collapse</title>

		<para>
		The streaming functions have proved quite useful in Triceps,
		in particular the inter-thread communications use an interface
		derived from them. But the ironic part is that
		coming up with the good examples of the streaming function usage in
		Triceps is surprisingly difficult. The flexibility of
		Triceps is the problem. If all you have is SQL, the streaming functions
		become pretty much a must. But if you can write the procedural code,
		most things are easier that way, with the normal procedural functions. 
		For a streaming function to become
		beneficial, it has to be written in SQLy primitives (such as tables,
		joins) and not be easily reducible to the procedural code.
		The streaming function examples that aren't big enough for their own file
		are collected in <pre>t/xFn.t</pre>.
		</para>

		<indexterm>
			<primary>streaming function</primary>
		</indexterm>
		<indexterm>
			<primary>Collapse</primary>
		</indexterm>
		<para>
		The most distilled example I've come up with is for the implementation of
		Collapse. The original implementation of Collapse is described in 
		<xref linkend="sc_other_collapse" xrefstyle="select: label quotedtitle pageabbrev"/>&xrsp;.
		The <pre>flush()</pre> there goes in a loop
		deleting the all rows from the state tables and sending them as rowops
		to the output.
		</para>

		<para>
		The deletion of all the rows can nowadays be done easier with the Table
		method <pre>clear()</pre>. However by itself it doesn't solve the problem of
		sending the output. It sends the deleted rows to the table's output
		label but we can't just connect the output of the state tables to the
		Collapse output: then it would also pick up all the intermediate
		changes! The data needs to be picked up from the tables output
		selectively, only in <pre>flush()</pre>.
		</para>

		<para>
		This makes it a good streaming function: the body of the function
		consists of running <pre>clear()</pre> on the state tables, and its result is
		whatever comes on the output labels of the tables.
		</para>

		<para>
		Since most of the logic remains unchanged, I've implemented this new
		version of Collapse in <pre>t/xFn.t</pre> as a subclass that extends and replaces some of the
		code with its own:
		</para>

<!-- t/xFn.t FnCollapse -->
<pre>
package FnCollapse;

sub CLONE_SKIP { 1; }

our @ISA=qw(Triceps::Collapse);

sub new # ($class, $optName => $optValue, ...)
{
	my $class = shift;
	my $self = $class->SUPER::new(@_);
	# Now add an FnReturn to the output of the dataset's tables.
	# One return is enough for both.
	# Also create the bindings for sending the data.
	foreach my $dataset (values %{$self->{datasets}}) {
		my $fret = Triceps::FnReturn->new(
			name => $self->{name} . "." . $dataset->{name} . ".retTbl",
			labels => [
				del => $dataset->{tbDelete}->getOutputLabel(),
				ins => $dataset->{tbInsert}->getOutputLabel(),
			],
		);
		$dataset->{fret} = $fret;

		# these variables will be compiled into the binding snippets
		my $lbOut = $dataset->{lbOut};
		my $unit = $self->{unit};
		my $OP_INSERT = &Triceps::OP_INSERT;
		my $OP_DELETE = &Triceps::OP_DELETE;

		my $fbind = Triceps::FnBinding->new(
			name => $self->{name} . "." . $dataset->{name} . ".bndTbl",
			on => $fret,
			unit => $unit,
			labels => [
				del => sub {
					if ($_[1]->isDelete()) {
						$unit->call($lbOut->adopt($_[1]));
					}
				},
				ins => sub {
					if ($_[1]->isDelete()) {
						$unit->call($lbOut->makeRowop($OP_INSERT, $_[1]->getRow()));
					}
				},
			],
		);
		$dataset->{fbind} = $fbind;
	}
	bless $self, $class;
	return $self;
}

# Override the base-class flush with a different implementation.
sub flush # ($self)
{
	my $self = shift;
	foreach my $dataset (values %{$self->{datasets}}) {
		# The binding takes care of producing and directing
		# the output. AutoFnBind will unbind when the block ends.
		my $ab = Triceps::AutoFnBind->new(
			$dataset->{fret} => $dataset->{fbind}
		);
		$dataset->{tbDelete}->clear();
		$dataset->{tbInsert}->clear();
	}
}
</pre>

		<indexterm>
			<primary>FnReturn</primary>
		</indexterm>
		<indexterm>
			<primary>FnBinding</primary>
		</indexterm>
		<para>
		<pre>new()</pre> adds the streaming function elements in each data set. They
		consist of two parts: FnReturn defines the return value of a streaming
		function (there is no formal definition of the body or the entry point
		since they are quite flexible), and FnBinding defines a call of the
		streaming function. In this case the function is called in only one
		place, so one FnBinding is defined. If called from multiple places,
		there would be multiple FnBindings.
		</para>

		<para>
		When a normal procedural function is called, the return address
		provides the connection to get the result back from it to the caller.
		In a streaming function, the FnBinding connects the result labels to
		the caller's further processing of the returned data. Unlike the
		procedural functions, the data is not returned in one step (run the
		function, compute the value, return it). Instead the return value of a
		streaming function is a stream of rowops. As each of them is sent to a
		return label, it goes through the binding and to the caller's further
		processing. Then the streaming function continues, producing the next
		rowop, and so on.
		</para>

		<para>
		If this sounds complicated, please realize that here we're dealing with
		the assembly language equivalent for streaming functions. I expect that
		over time the more high-level primitives will be developed and it 
		will become easier.
		</para>

		<para>
		The second source of complexity is that the arguments of a streaming
		function are not computed in one step either. You don't normally have a
		full set of rows to send to a streaming function in one go. Instead you
		set up the streaming call to bind the result, then you pump the argument rowops
		to the function's input, creating them in whatever way you wish.
		</para>

		<para>
		Getting back to the definition of a streaming function, FnReturn
		defines a set of labels, each with a logical name. In this case the
		names are <quote>del</quote> and <quote>ins</quote>. The labels inside FnReturn are a special
		variety of dummy labels, but they are chained to some real labels that
		send the result of the function. The snippet
		</para>

<pre>
del => $dataset->{tbDelete}->getOutputLabel(),
</pre>

		<para>
		says <quote>create a return label named <quote>del</quote> and chain it from the
		tbDelete's output label</quote>. There are more details to the naming and label
		creation but let's not get bogged in them now.
		</para>

		<para>
		The FnBinding defines a matching set of labels, with the same logical
		names. It's like a receptacle and a plug: you put the plug into the
		receptacle and get the data flowing, you unplug it and the data flow
		stops. The Perl version of FnBinding provides a convenience: when it
		gets a code reference instead of a label, it automatically creates a
		label with that code for its handler.
		</para>

		<para>
		In this case both binding labels forward the data to the Collapse's
		output label. Only the one for the Insert table has to change the
		opcodes to OP_INSERT. The check
		</para>

<pre>
if ($_[1]->isDelete()) ...
</pre>

		<para>
		is really redundant, to be on the safe side, since we know that when
		the data will be flowing, all of it will be coming from the table
		clearing and have the opcodes of OP_DELETE.
		</para>

		<indexterm>
			<primary>AutoFnBind</primary>
		</indexterm>
		<indexterm>
			<primary>binding</primary>
		</indexterm>
		<para>
		The actual call happens in <pre>flush()</pre>: Triceps::AutoFnBind is a constructor
		of the scope object that does the <quote>plug into receptable</quote>
		thing, with automatic unplugging when the object returned by it gets
		destroyed on leaving the block scope. If you want to do things
		manually, FnReturn has the methods <pre>push()</pre> and
		<pre>pop()</pre> but the scoped binding is safer and easier.  Once the
		binding is done, the data is sent through the function by calling
		<pre>clear()</pre> on both tables. And then the block ends,
		<pre>$ab</pre> get destroyed, AutoFnBind destructor undoes the binding, and 
		thus the streaming function call completes.
		</para>

		<para>
		The result produced by this version of Collapse is exactly the same as
		by the original version. And even when we get down to grits, it's
		produced with the exact same logical sequence: the rows are sent out as
		they are deleted from the state tables. But it's structured
		differently: instead of the procedural deletion and sending of the
		rows, the internal machinery of the tables gets invoked, and the
		results of that machinery are then converted to the form suitable for
		the collapse results and propagated to the output.
		</para>

		<para>
		Philosophically, it could be argued, what is the body of this function?
		Is it just the internal logic of the table delection, that gets
		triggered by <pre>clear()</pre> in the caller? Or are the <pre>clear()</pre> calls also a
		part of the function body? But it practice it just doesn't matter,
		whatever. 
		</para>
	</sect1>

	<sect1 id="sc_strf_keyed_collapse">
		<title>Collapse with grouping by key with streaming functions</title>

		<indexterm>
			<primary>streaming function</primary>
		</indexterm>
		<indexterm>
			<primary>Collapse</primary>
		</indexterm>
		<para>
		The Collapse as shown before sends all the collected deletes before all
		the collected inserts. For example, if it has collected the updates for
		four rows, the output will be (assuming that the Collapse element is
		named <pre>collapse</pre> and the data set in it is named <pre>idata</pre>):
		</para>

<!-- t/xFn.t doCollapse1 -->
<exdump>
collapse.idata.out OP_DELETE local_ip="3.3.3.3" remote_ip="7.7.7.7" bytes="100"
collapse.idata.out OP_DELETE local_ip="2.2.2.2" remote_ip="6.6.6.6" bytes="100"
collapse.idata.out OP_DELETE local_ip="4.4.4.4" remote_ip="8.8.8.8" bytes="100"
collapse.idata.out OP_DELETE local_ip="1.1.1.1" remote_ip="5.5.5.5" bytes="100"
collapse.idata.out OP_INSERT local_ip="3.3.3.3" remote_ip="7.7.7.7" bytes="300"
collapse.idata.out OP_INSERT local_ip="2.2.2.2" remote_ip="6.6.6.6" bytes="300"
collapse.idata.out OP_INSERT local_ip="4.4.4.4" remote_ip="8.8.8.8" bytes="300"
collapse.idata.out OP_INSERT local_ip="1.1.1.1" remote_ip="5.5.5.5" bytes="300"
</exdump>

		<para>
		What if you want the updates produced as deletes immediately followed
		by the matching inserts with the same key?  Like this:
		</para>

<!-- t/xFn.t doCollapse2 -->
<exdump>
collapse.idata.out OP_DELETE local_ip="3.3.3.3" remote_ip="7.7.7.7" bytes="100"
collapse.idata.out OP_INSERT local_ip="3.3.3.3" remote_ip="7.7.7.7" bytes="300"
collapse.idata.out OP_DELETE local_ip="2.2.2.2" remote_ip="6.6.6.6" bytes="100"
collapse.idata.out OP_INSERT local_ip="2.2.2.2" remote_ip="6.6.6.6" bytes="300"
collapse.idata.out OP_DELETE local_ip="4.4.4.4" remote_ip="8.8.8.8" bytes="100"
collapse.idata.out OP_INSERT local_ip="4.4.4.4" remote_ip="8.8.8.8" bytes="300"
collapse.idata.out OP_DELETE local_ip="1.1.1.1" remote_ip="5.5.5.5" bytes="100"
collapse.idata.out OP_INSERT local_ip="1.1.1.1" remote_ip="5.5.5.5" bytes="300"
</exdump>

		<para>
		With the procedural version it would have required doing a look-up in the Insert
		table after processing each row in the Delete table and handling it if
		found. So I've left it out to avoid complicating that example. But in
		the streaming function form it becomes easy, just change the binding 
		of the <quote>del</quote> label a little bit:
		</para>

<!-- t/xFn.t FnCollapseClose, selected lines -->
<pre>
		my $lbInsInput = $dataset->{tbInsert}->getInputLabel();

		my $fbind = Triceps::FnBinding->new(
			name => $self->{name} . "." . $dataset->{name} . ".bndTbl",
			on => $fret,
			unit => $unit,
			labels => [
				del => sub {
					if ($_[1]->isDelete()) {
						$unit->call($lbOut->adopt($_[1]));
						# If the INSERT is available after this DELETE, this
						# will produce it.
						$unit->call($lbInsInput->adopt($_[1]));
					}
				},
				ins => sub {
					if ($_[1]->isDelete()) {
						$unit->call($lbOut->makeRowop($OP_INSERT, $_[1]->getRow()));
					}
				},
			],
		);
</pre>

		<para>
		The <quote>del</quote> binding first sends the result out as usual and then forwards
		the DELETE rowop to the Insert table's input. Which then causes the
		INSERT rowop to be sent if a match is found. Mind you, the look-up and
		conditional processing still happens. But now it all happens inside the
		table machinery, all you need to do is add one more line to invoke it.
		</para>

		<para>
		Let's talk through in a little more detail, what happens when the clearing of
		the Delete table deletes the row with <pre>(local_ip="3.3.3.3" remote_ip="7.7.7.7")</pre>.
		</para>

		<orderedlist>
			<listitem>
			The Delete table sends a rowop with this row and OP_DELETE to its
			output label <pre>collapse.idata.tbDelete.out</pre>.
			</listitem>
			<listitem>
			Which then gets forwarded to a chained label in the FnReturn,
			<pre>collapse.idata.retTbl.del</pre>.
			</listitem>
			<listitem>
			FnReturn has an FnBinding pushed into it, so the rowop passes to the
			matching label in the binding, <pre>collapse.idata.bndTbl.del</pre>.
			</listitem>
			<listitem>
			The Perl handler of that label gets called, first forwards the
			rowop to the Collapse output label <pre>collapse.idata.out</pre>, and then to
			the Insert table's input label <pre>collapse.idata.tbInsert.in</pre>.
			</listitem>
			<listitem>
			The Insert table looks up the row by the key, finds it, removes it
			from the table, and sends an OP_DELETE rowop to its output label
			<pre>collapse.idata.tbInsert.out</pre>.
			</listitem>
			<listitem>
			Which then gets forwarded to a chained label in the FnReturn,
			<pre>collapse.idata.retTbl.ins</pre>.
			</listitem>
			<listitem>
			FnReturn has an FnBinding pushed into it, so the rowop passes to the
			matching label in the binding, <pre>collapse.idata.bndTbl.ins</pre>.
			</listitem>
			<listitem>
			The Perl handler of that label gets called and sends the rowop with
			the opcode changed to OP_INSERT to the Collapse output label
			<pre>collapse.idata.out</pre>.
			</listitem>
		</orderedlist>

		<para>
		It's a fairly complicated sequence but all you needed to do was to add
		one line of code. The downside of course is that if something goes not
		the way you expected, you'd have to trace and understand the whole
		long sequence (that's the typical trouble with the SQL-based systems).
		</para>

		<para>
		When the INSERTs are sent after DELETEs, their rows are removed
		from the Insert table too, so the following <pre>clear()</pre> of the Insert table
		won't find them any more and won't send any duplicates; it will send
		only the inserts for which there were no matching deletes.
		</para>

		<para>
		And of course if there is only a DELETE collected for a certain
		key, not an update, there will be no matching row in the Insert
		table, so the forwarded DELETE request will have no effect
		and produce no output from the Insert table.
		</para>

		<para>
		You may notice that the code in the <quote>del</quote> handler only forwards the
		rows around, and that can be replaced by a chaining:
		</para>

<!-- t/xFn.t FnCollapseClose3, selected lines -->
<pre>
		my $lbDel = $unit->makeDummyLabel(
			$dataset->{tbDelete}->getOutputLabel()->getRowType(), 
			$self->{name} . "." . $dataset->{name} . ".lbDel");
		$lbDel->chain($lbOut);
		$lbDel->chain($lbInsInput);

		my $fbind = Triceps::FnBinding->new(
			name => $self->{name} . "." . $dataset->{name} . ".bndTbl",
			on => $fret,
			unit => $unit,
			labels => [
				del => $lbDel,
				ins => sub {
					$unit->call($lbOut->makeRowop($OP_INSERT, $_[1]->getRow()));
				},
			],
		);
</pre>

		<indexterm>
			<primary>FnBinding</primary>
		</indexterm>
		<para>
		This shows another way of label definition in FnBinding: an actual
		label is created first and then given to the FnBinding, instead of letting
		it automatically create a label from the code. The condition
		<quote><pre>if ($_[1]->isDelete())</pre></quote> has been removed 
		from the <quote>ins</quote> part, since
		it's really redundant and the <quote>del</quote> part with its chaining doesn't do
		this check anyway.
		</para>

		<para>
		This code works just as well and even more efficiently than the
		previous version, since no Perl code needs to be invoked for <quote>del</quote>, it
		all propagates internally through the chaining. However the price is
		that the DELETE rowops coming out of the output label will have the
		head-of-the-chain label in them:
		</para>

<!-- t/xFn.t doCollapse3 -->
<exdump>
collapse.idata.lbDel OP_DELETE local_ip="3.3.3.3" remote_ip="7.7.7.7" bytes="100"
collapse.idata.out OP_INSERT local_ip="3.3.3.3" remote_ip="7.7.7.7" bytes="300"
collapse.idata.lbDel OP_DELETE local_ip="2.2.2.2" remote_ip="6.6.6.6" bytes="100"
collapse.idata.out OP_INSERT local_ip="2.2.2.2" remote_ip="6.6.6.6" bytes="300"
collapse.idata.lbDel OP_DELETE local_ip="4.4.4.4" remote_ip="8.8.8.8" bytes="100"
collapse.idata.out OP_INSERT local_ip="4.4.4.4" remote_ip="8.8.8.8" bytes="300"
collapse.idata.lbDel OP_DELETE local_ip="1.1.1.1" remote_ip="5.5.5.5" bytes="100"
collapse.idata.out OP_INSERT local_ip="1.1.1.1" remote_ip="5.5.5.5" bytes="300"
</exdump>

		<para>
		The <quote>ins</quote> side can't be handled just by chaining because it has to
		replace the opcode in the rowops. Another potential way to handle
		this would be to define various preprogrammed label types in &Cpp; for many primitive
		operations, like replacing the opcode, and then build the models by combining
		them.
		</para>

		<indexterm>
			<primary>recursion</primary>
		</indexterm>
		<para>
		The final item is that the code shown in this section involved a recursive
		call of the streaming function. Its output from the <quote>del</quote> label got fed
		back to the function, producing more output on the <quote>ins</quote> label. This
		worked because it invoked a different code path in the streaming
		function than the one that produced the <quote>del</quote> data. If it were to form
		a topological loop back to the same path with the same labels, that
		would have been an error. The more advanced use of recursion is
		possible and will be discussed in more detail later. 
		</para>
	</sect1>
</chapter>
